set.seed(1)
N = 1000
K = 10
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
### Regression models
summary(lm(Y~X))
summary(lm(Y~X[,1]))
summary(lm(Y~X[,2]))
### Regression models
summary(lm(Y~X))
### Regression models
summary(lm(Y~X))
summary(lm(Y~X[,1]))
summary(lm(Y~X[,2]))
cov(X[,1], X[,2]) ### Illustrates the positive covariance
X2
hist(X2)
plot(U)
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 10
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.4)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 10
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.2)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
### Regression models
summary(lm(Y~X))
summary(lm(Y~X[,1]))
summary(lm(Y~X[,2]))
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
install.packages("devtools")
library(devtools)
install_github("dpuelz/BicliqueRT")
library(devtools)
install_github("dpuelz/BicliqueRT")
library(BicliqueRT)
hello
blah
install.packages("swirl")
library(swirl)
install_course_github("kosukeimai","qss-swirl")
library()
swirl()
install_course("qss-swirl")
install_course("qss-swirl")
install_course("qss-swirl")
library(swirl) # load the swirl package
install_course_github("kosukeimai", "qss-swirl")
swirl()
8-2
10^2
sqrt(9)
remotes::install_github("kosukeimai/qss-package", build_vignettes = TRUE)
test <- function(seed){
res <- seed + seed
}
test(1)
test(1)
test <- function(seed){
res <- seed + seed
}
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
##
test <- function(seed){
res <- seed + seed
res
}
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
setwd("~/Dropbox/SalemCenter/classes/PRL/Policy-Research-Laboratory/code")
####
# Marriage and the Medici clan
####
## load the igraph package
library(igraph)
medici = as.matrix(read.table("../data/medici.txt"))
medici
marriage = graph.edgelist(medici, directed=FALSE)
marriage
## set some color atributes (V() gives back the 'vertices' = nodes)
V(marriage)$color = "orange"
V(marriage)["Medici"]$color = "lightblue"
V(marriage)$frame.color = 0
V(marriage)$label.color = "black"
## plot it
plot(marriage, edge.curved=FALSE)
## print the degree for each family
sort(degree(marriage))
PtoA = get.shortest.paths(marriage, from="Peruzzi", to="Acciaiuoli")
PtoA
allPtoA = all_shortest_paths(marriage, from="Peruzzi", to="Acciaiuoli")
allPtoA
PtoA$vpath[[1]]
GtoS = get.shortest.paths(marriage, from="Ginori", to="Strozzi")
GtoS$vpath[[1]]
E(marriage)$width = 2
E(marriage)$color = "grey"
E(marriage, path=PtoA$vpath[[1]])$color = "purple"
E(marriage, path=GtoS$vpath[[1]])$color = "darkgreen"
plot(marriage)
## print the betweenness for each family
sort(round(betweenness(marriage),1))
medici
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
# Association rule mining
# Adapted from code by Matt Taddy
# Read in playlists from users
# This is in "long" format -- every row is a single artist-listener pair
playlists_raw = read.csv("../data/playlists.csv")
str(playlists_raw)
summary(playlists_raw)
# Turn user into a factor
playlists_raw$user = factor(playlists_raw$user)
# First create a list of baskets: vectors of items by consumer
# Analagous to bags of words
# apriori algorithm expects a list of baskets in a special format
# In this case, one "basket" of songs per user
# First split data into a list of artists for each user
playlists = split(x=playlists_raw$artist, f=playlists_raw$user)
## Remove duplicates ("de-dupe")
playlists = lapply(playlists, unique)
## Cast this variable as a special arules "transactions" class.
playtrans = as(playlists, "transactions")
summary(playtrans)
# Now run the 'apriori' algorithm
# Look at rules with support > .005 & confidence >.1 & length (# artists) <= 5
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=5))
# Look at the output... so many rules!
inspect(musicrules)
## Choose a subset
inspect(subset(musicrules, subset=lift > 5))
inspect(subset(musicrules, subset=confidence > 0.6))
inspect(subset(musicrules, subset=lift > 10 & confidence > 0.5))
# plot all the rules in (support, confidence) space
# notice that high lift rules tend to have low support
plot(musicrules)
# can swap the axes and color scales
plot(musicrules, measure = c("support", "lift"), shading = "confidence")
# "two key" plot: coloring is by size (order) of item set
plot(musicrules, method='two-key plot')
# can now look at subsets driven by the plot
inspect(subset(musicrules, support > 0.035))
inspect(subset(musicrules, confidence > 0.7))
# graph-based visualization
sub1 = subset(musicrules, subset=confidence > 0.01 & support > 0.005)
summary(sub1)
plot(sub1, method='graph')
?plot.rules
plot(head(sub1, 100, by='lift'), method='graph')
# export
saveAsGraph(head(musicrules, n = 1000, by = "lift"), file = "musicrules.graphml")
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
# Association rule mining
# Read in playlists from users
# This is in "long" format -- every row is a single artist-listener pair
playlists_raw = read.csv("../data/playlists.csv")
library(tidyverse)
library(arules)  # has a big ecosystem of packages built around it
library(arulesViz)
# Association rule mining
# Read in playlists from users
# This is in "long" format -- every row is a single artist-listener pair
playlists_raw = read.csv("../data/playlists.csv")
str(playlists_raw)
summary(playlists_raw)
# Turn user into a factor
playlists_raw$user = factor(playlists_raw$user)
playlists_raw$user
playlists = split(x=playlists_raw$artist, f=playlists_raw$user)
playlists = lapply(playlists, unique)
playtrans = as(playlists, "transactions")
summary(playtrans)
musicrules = apriori(playtrans,
parameter=list(support=.005, confidence=.1, maxlen=5))
inspect(musicrules)
inspect(subset(musicrules, subset=lift > 5))
plot(musicrules)
plot(musicrules, measure = c("support", "lift"), shading = "confidence")
plot(musicrules, method='two-key plot')
# can now look at subsets driven by the plot
inspect(subset(musicrules, support > 0.035))
inspect(subset(musicrules, confidence > 0.7))
# graph-based visualization
sub1 = subset(musicrules, subset=confidence > 0.01 & support > 0.005)
summary(sub1)
plot(sub1, method='graph')
dev.off()
dev.off()
