summary(lm(Y~X))
### Regression models
summary(lm(Y~X))
summary(lm(Y~X[,1]))
summary(lm(Y~X[,2]))
cov(X[,1], X[,2]) ### Illustrates the positive covariance
X2
hist(X2)
plot(U)
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 10
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.4)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 10
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.2)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
### Regression models
summary(lm(Y~X))
summary(lm(Y~X[,1]))
summary(lm(Y~X[,2]))
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
library(MASS)
library(FNN)
set.seed(1)
N = 1000
K = 5
### 70 percentage of schools were assigned to 6ft, i.e. 1: 6ft, 0: 4ft
X1 <- rbinom(n = N, size = 1, prob = 0.7)
### Spatial Location: those with 6ft policy have spatial locations between 0 and 1 for both coordinates and those with 4ft policy have spatial locations between 0.3 and 0.6 for both coordinates
U1 <- runif(n = N, 0.3, 0.6)*(1-X1)
U2 <- runif(n = N, 0.3, 0.6)*(1-X1)
U1 <- U1 + runif(n = N, 0, 1)*X1
U2 <- U2 + runif(n = N, 0, 1)*X1
U <- cbind(U1, U2)
X2 <- rep(NA, N)
KNN <- get.knn(U, k = K)
ind <- KNN$nn.ind ### Contains index of 10 closest elements
for(i in 1:N){
X2[i] <- sum(X1[ind[i,]])/K
### X2 is the proportion of schools around which had 6ft policy
}
X <- cbind(X1, X2)
Y <- X%*%c(1, -1.2) + rnorm(n = N, 0, 1)
cov(Y, X[,1]) ### Illustrates the negative covariance
cov(X[,1], X[,2]) ### Illustrates the positive covariance
install.packages("devtools")
library(devtools)
install_github("dpuelz/BicliqueRT")
library(devtools)
install_github("dpuelz/BicliqueRT")
library(BicliqueRT)
hello
blah
install.packages("swirl")
library(swirl)
install_course_github("kosukeimai","qss-swirl")
library()
swirl()
install_course("qss-swirl")
install_course("qss-swirl")
install_course("qss-swirl")
library(swirl) # load the swirl package
install_course_github("kosukeimai", "qss-swirl")
swirl()
8-2
10^2
sqrt(9)
remotes::install_github("kosukeimai/qss-package", build_vignettes = TRUE)
test <- function(seed){
res <- seed + seed
}
test(1)
test(1)
test <- function(seed){
res <- seed + seed
}
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
##
test <- function(seed){
res <- seed + seed
res
}
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
test(1)
MPs <- read.csv("../data/MPs.csv")
setwd("~/Dropbox/SalemCenter/classes/PRL/Policy-Research-Laboratory/code")
MPs <- read.csv("../data/MPs.csv")
MPs.labour <- subset(MPs, subset = (party == "labour"))
MPs.tory <- subset(MPs, subset = (party == "tory"))
head(MPs)
MPs.labour <- subset(MPs, subset = (party == "labour"))
MPs.tory <- subset(MPs, subset = (party == "tory"))
labour.fit1 <- lm(ln.net ~ margin,
data = MPs.labour[MPs.labour$margin < 0, ])
labour.fit2 <- lm(ln.net ~ margin,
data = MPs.labour[MPs.labour$margin > 0, ])
## two regressions for Tory: negative and positive margin
tory.fit1 <- lm(ln.net ~ margin, data = MPs.tory[MPs.tory$margin < 0, ])
tory.fit2 <- lm(ln.net ~ margin, data = MPs.tory[MPs.tory$margin > 0, ])
## Labour: range of predictions
y1l.range <- c(min(MPs.labour$margin), 0) # min to 0
y2l.range <- c(0, max(MPs.labour$margin)) # 0 to max
y1l.range <- c(min(MPs.labour$margin), 0) # min to 0
y2l.range <- c(0, max(MPs.labour$margin)) # 0 to max
## prediction
y1.labour <- predict(labour.fit1, newdata = data.frame(margin = y1l.range))
y2.labour <- predict(labour.fit2, newdata = data.frame(margin = y2l.range))
## Tory: range of predictions
y1t.range <- c(min(MPs.tory$margin), 0) # min to 0
y2t.range <- c(0, max(MPs.tory$margin)) # 0 to max
## predict outcome
y1.tory <- predict(tory.fit1, newdata = data.frame(margin = y1t.range))
y2.tory <- predict(tory.fit2, newdata = data.frame(margin = y2t.range))
plot(MPs.labour$margin, MPs.labour$ln.net, main = "Labour",
xlim = c(-0.5, 0.5), ylim = c(6, 18), xlab = "Margin of victory",
ylab = "log net wealth at death")
abline(v = 0, lty = "dashed")
plot(MPs.labour$margin, MPs.labour$ln.net, main = "Labour",
xlim = c(-0.5, 0.5), ylim = c(6, 18), xlab = "Margin of victory",
ylab = "log net wealth at death",pch=19,col='gray')
abline(v = 0, lty = "dashed")
## add regression lines
lines(y1l.range, y1.labour, col = "blue")
lines(y2l.range, y2.labour, col = "blue")
lines(y1l.range, y1.labour, col = "blue",lwd=2)
lines(y2l.range, y2.labour, col = "blue",lwd=2)
## scatterplot with regression lines for tory
plot(MPs.tory$margin, MPs.tory$ln.net, main = "Tory", xlim = c(-0.5, 0.5),
ylim = c(6, 18), xlab = "Margin of victory",
ylab = "log net wealth at death")
abline(v = 0, lty = "dashed")
## add regression lines
lines(y1t.range, y1.tory, col = "blue")
lines(y2t.range, y2.tory, col = "blue")
## scatterplot with regression lines for labour
plot(MPs.labour$margin, MPs.labour$ln.net, main = "Labour",
xlim = c(-0.5, 0.5), ylim = c(6, 18), xlab = "Margin of victory",
ylab = "log net wealth at death",pch=19,col='gray')
abline(v = 0, lty = "dashed")
## add regression lines
lines(y1l.range, y1.labour, col = "blue",lwd=2)
lines(y2l.range, y2.labour, col = "blue",lwd=2)
## scatterplot with regression lines for tory
plot(MPs.tory$margin, MPs.tory$ln.net, main = "Tory", xlim = c(-0.5, 0.5),
ylim = c(6, 18), xlab = "Margin of victory",
ylab = "log net wealth at death",pch=19,col='gray')
abline(v = 0, lty = "dashed")
## add regression lines
lines(y1t.range, y1.tory, col = "blue",lwd=2)
lines(y2t.range, y2.tory, col = "blue",lwd=2)
## average net wealth for Tory MP
tory.MP <- exp(y2.tory[1])
tory.MP
## average net wealth for Tory non-MP
tory.nonMP <- exp(y1.tory[2])
tory.nonMP
## causal effect in pounds (what is the conclusion here?)
tory.MP - tory.nonMP
boot_RD <- function(){
boot_data <- resample(MPs.tory)
tory.fit1 <- lm(ln.net ~ margin, data = boot_data[boot_data$margin < 0, ])
tory.fit2 <- lm(ln.net ~ margin, data = boot_data[boot_data$margin > 0, ])
networth_diff <- exp(coef(tory.fit2)[1]) - exp(coef(tory.fit1)[1])
networth_diff
}
tory_samp = replicate(1000,boot_RD())
library(mosaic)
tory_samp = replicate(1000,boot_RD())
hist(tory_samp)
abline(v=0,col=2,lwd=3)
confint(tory_samp,level=0.95)
setwd("~/Dropbox/Panos/causal-Wellness/wellness_bcf/analysis/rscripts")
load('outcomes_QJE.RData')
head(outcomes_QJE)
data = outcomes_QJE; remove(outcomes_QJE)
unique(data$AnalysisID)
load('outcomes_QJE.RData')
head(outcomes_QJE)
data = outcomes_QJE; remove(outcomes_QJE)
colnames(data)
data$hra_c_nomiss
sum(data$hra_c_nomiss)
sum(data$treat)
data$treat
unique(data$AnalysisID)
length(unique(data$AnalysisID))
sum(!is.na(data$treat))
which(!is.na(data$treat))
iQJE = which(!is.na(data$treat))
load('outcomes_QJE.RData')
head(outcomes_QJE)
data = outcomes_QJE; remove(outcomes_QJE)
# subsetting to units directly in the study
iQJE = which(!is.na(data$treat))
load('outcomes_QJE.RData')
head(outcomes_QJE)
data = outcomes_QJE; remove(outcomes_QJE)
# subsetting to units directly in the study
iQJE = which(!is.na(data$treat))
data_QJE = data[iQJE,]
colnames(data_QJE)
data$hra_c
data_QJE$hra_c
data_QJE$hra_c_nomiss
participate_indices = which(data_QJE$hra_c_nomiss==1)
treatment_indices = which(data_QJE$treat==1)
setwd("~/Library/Containers/com.apple.mail/Data/Library/Mail Downloads/BB2642E6-7F46-49D0-8B87-A5CAA87642A3")
setwd("~/Desktop")
setwd("~/Dropbox/SalemCenter/classes/PRL/Policy-Research-Laboratory/code")
library(ggplot2)
library(LICORS)  # for kmeans++
library(foreach)
library(mosaic)
cars = read.csv('../data/cars.csv', header=TRUE)
summary(cars)
# Center and scale the data
X = cars[,-(1:9)]
X = scale(X, center=TRUE, scale=TRUE)
# Extract the centers and scales from the rescaled data (which are named attributes)
mu = attr(X,"scaled:center")
sigma = attr(X,"scaled:scale")
# Run k-means with 6 clusters and 25 starts
clust1 = kmeans(X, 6, nstart=25)
clust1$center  # not super helpful
clust1$center[1,]*sigma + mu
clust1$center[2,]*sigma + mu
clust1$center[4,]*sigma + mu
# Which cars are in which clusters?
which(clust1$cluster == 1)
which(clust1$cluster == 2)
which(clust1$cluster == 3)
which(clust1$cluster == 4)
which(clust1$cluster == 5)
qplot(Weight, Length, data=cars, color=factor(clust1$cluster))
qplot(Horsepower, CityMPG, data=cars, color=factor(clust1$cluster))
